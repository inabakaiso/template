data:
  train_data_path: "../input/train.csv"
  test_data_path: "../input/train.csv"
  train_txt_path: "../input/train"
  test_txt_path: "../input/test"
  output_dir_path: "output"
  input_dir_path: "../input"
cv_strategy:
  seed: 42
  num_split: 4
  shuffle: true
model:
  model_name: "microsoft/deberta-v3-base"
  target_size: 3
tokenizer:
  tokenizer_name: ${model.model_name}
dataset:
  batch_size: 8
  num_workers: 4
  max_len: 512
  train: true
scheduler:
  scheduler_name: "Cosine_Annealing"
  num_warmup_steps: 0
  num_cycles: 0.5
training:
  dropout: 0.2
  debug: false
  batch_scheduler: true
  gradient_checkpoint: false
  apex: true
  epochs: 5
  batch_size: ${dataset.batch_size}
  weight_decay: 0.01
  max_grad_norm: 1000
  eps: 0.000001
  min_lr: 0.0000001
  t_0: 500
  encoder_lr: 0.00002
  decoder_lr: 0.00002
  print_freq: 50
  gradient_accumulation_steps: 1
  accumulation_steps: 1
  gpu_optimize_config:
    fp16: true
    freezing: true
    optim8bit: true
    gradient_checkpoint: true